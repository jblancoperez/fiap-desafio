{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/jblancoperez/fiap-desafio/blob/main/C%C3%B3pia_de_00_analise.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "axOqrhU9D8uy",
    "outputId": "0dcda0b8-daf4-4a20-ec14-db793ed9f606"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sn\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import sys\n",
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier,AdaBoostClassifier,ExtraTreesClassifier\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor,AdaBoostRegressor,ExtraTreesRegressor\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#!{sys.executable} -m pip install -U pandas-profiling[notebook]\n",
    "#!jupyter nbextension enable --py widgetsnbextension\n",
    "\n",
    "#!{sys.executable} -m pip install -U lafrom lazypredict.Supervised import LazyClassifier, LazyRegressor\n",
    "\n",
    "def cm_to_inch(value):\n",
    "    return value/2.54\n",
    "#arquivo = pd.read_csv('https://raw.githubusercontent.com/jblancoperez/fiap-desafio/main/solicitacoescredito.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arquivo = pd.read_csv('./solicitacoescredito.csv')\n",
    "aprovadosAnalista=arquivo.loc[arquivo['status'].isin(['AprovadoAnalista','AprovadoComite'])]\n",
    "aprovadosAnalista.head()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature selection class to eliminate multicollinearity\n",
    "\n",
    "#Baseado em  https://www.youtube.com/watch?v=ioXKxulmwVQ&feature=youtu.be\n",
    "class MultiCollinearityEliminator():\n",
    "    \n",
    "    #Class Constructor\n",
    "    def __init__(self, df, target, threshold):\n",
    "        self.df = df\n",
    "        self.target = target\n",
    "        self.threshold = threshold\n",
    "\n",
    "    #Method to create and return the feature correlation matrix dataframe\n",
    "    def createCorrMatrix(self, include_target = False):\n",
    "        #Checking we should include the target in the correlation matrix\n",
    "        if (include_target == False):\n",
    "            df_temp = self.df.drop([self.target], axis =1)\n",
    "            \n",
    "            #Setting method to Pearson to prevent issues in case the default method for df.corr() gets changed\n",
    "            #Setting min_period to 30 for the sample size to be statistically significant (normal) according to \n",
    "            #central limit theorem\n",
    "            corrMatrix = df_temp.corr(method='pearson', min_periods=30).abs()\n",
    "        #Target is included for creating the series of feature to target correlation - Please refer the notes under the \n",
    "        #print statement to understand why we create the series of feature to target correlation\n",
    "        elif (include_target == True):\n",
    "            corrMatrix = self.df.corr(method='pearson', min_periods=30).abs()\n",
    "        return corrMatrix\n",
    "\n",
    "    #Method to create and return the feature to target correlation matrix dataframe\n",
    "    def createCorrMatrixWithTarget(self):\n",
    "        #After obtaining the list of correlated features, this method will help to view which variables \n",
    "        #(in the list of correlated features) are least correlated with the target\n",
    "        #This way, out the list of correlated features, we can ensure to elimate the feature that is \n",
    "        #least correlated with the target\n",
    "        #This not only helps to sustain the predictive power of the model but also helps in reducing model complexity\n",
    "        \n",
    "        #Obtaining the correlation matrix of the dataframe (along with the target)\n",
    "        corrMatrix = self.createCorrMatrix(include_target = True)                           \n",
    "        #Creating the required dataframe, then dropping the target row \n",
    "        #and sorting by the value of correlation with target (in asceding order)\n",
    "        corrWithTarget = pd.DataFrame(corrMatrix.loc[:,self.target]).drop([self.target], axis = 0).sort_values(by = self.target)                    \n",
    "        #print(corrWithTarget, '\\n')\n",
    "        return corrWithTarget\n",
    "\n",
    "    #Method to create and return the list of correlated features\n",
    "    def createCorrelatedFeaturesList(self):\n",
    "        #Obtaining the correlation matrix of the dataframe (without the target)\n",
    "        corrMatrix = self.createCorrMatrix(include_target = False)                          \n",
    "        colCorr = []\n",
    "        #Iterating through the columns of the correlation matrix dataframe\n",
    "        for column in corrMatrix.columns:\n",
    "            #Iterating through the values (row wise) of the correlation matrix dataframe\n",
    "            for idx, row in corrMatrix.iterrows():                                            \n",
    "                if(row[column]>self.threshold) and (row[column]<1):\n",
    "                    #Adding the features that are not already in the list of correlated features\n",
    "                    if (idx not in colCorr):\n",
    "                        colCorr.append(idx)\n",
    "                    if (column not in colCorr):\n",
    "                        colCorr.append(column)\n",
    "        #print(colCorr, '\\n')\n",
    "        return colCorr\n",
    "\n",
    "    #Method to eliminate the least important features from the list of correlated features\n",
    "    def deleteFeatures(self, colCorr):\n",
    "        #Obtaining the feature to target correlation matrix dataframe\n",
    "        corrWithTarget = self.createCorrMatrixWithTarget()                                  \n",
    "        for idx, row in corrWithTarget.iterrows():\n",
    "            #print(idx, '\\n')\n",
    "            if (idx in colCorr):\n",
    "                self.df = self.df.drop(idx, axis =1)\n",
    "                break\n",
    "        return self.df\n",
    "\n",
    "    #Method to run automatically eliminate multicollinearity\n",
    "    def autoEliminateMulticollinearity(self):\n",
    "        #Obtaining the list of correlated features\n",
    "        colCorr = self.createCorrelatedFeaturesList()                                       \n",
    "        while colCorr != []:\n",
    "            #Obtaining the dataframe after deleting the feature (from the list of correlated features) \n",
    "            #that is least correlated with the taregt\n",
    "            self.df = self.deleteFeatures(colCorr)\n",
    "            #Obtaining the list of correlated features\n",
    "            colCorr = self.createCorrelatedFeaturesList()                                     \n",
    "        return self.df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                             valorAprovado\n",
      "percentualProtestos               0.008198\n",
      "eprimeira                         0.014801\n",
      "dashboardCorrelacao               0.030369\n",
      "valorSolicitado                   0.048894\n",
      "duplicatasAReceber                0.049847\n",
      "anoFundacao                       0.052694\n",
      "passivoCirculante                 0.056105\n",
      "margemBrutaAcumulada              0.059794\n",
      "diferencaPercentualRisco          0.060300\n",
      "percentualRisco                   0.060300\n",
      "maiorAtraso                       0.067067\n",
      "totalAtivo                        0.070653\n",
      "scorePontualidade                 0.081615\n",
      "ativoCirculante                   0.090800\n",
      "prazoMedioRecebimentoVendas       0.099644\n",
      "totalPatrimonioLiquido            0.101533\n",
      "endividamento                     0.141683\n",
      "margemBruta                       0.173502\n",
      "periodoDemonstrativoEmMeses       0.182527\n",
      "faturamentoBruto                  0.188339\n",
      "custos                            0.199530\n",
      "estoque                           0.205265\n",
      "limiteEmpresaAnaliseCredito       0.240776\n",
      "capitalSocial                     0.355262\n",
      "titulosEmAberto                   0.531340 \n",
      "\n",
      "                             valorAprovado\n",
      "percentualProtestos               0.008198\n",
      "eprimeira                         0.014801\n",
      "dashboardCorrelacao               0.030369\n",
      "valorSolicitado                   0.048894\n",
      "anoFundacao                       0.052694\n",
      "passivoCirculante                 0.056105\n",
      "margemBrutaAcumulada              0.059794\n",
      "diferencaPercentualRisco          0.060300\n",
      "percentualRisco                   0.060300\n",
      "maiorAtraso                       0.067067\n",
      "totalAtivo                        0.070653\n",
      "scorePontualidade                 0.081615\n",
      "ativoCirculante                   0.090800\n",
      "prazoMedioRecebimentoVendas       0.099644\n",
      "totalPatrimonioLiquido            0.101533\n",
      "endividamento                     0.141683\n",
      "margemBruta                       0.173502\n",
      "periodoDemonstrativoEmMeses       0.182527\n",
      "faturamentoBruto                  0.188339\n",
      "custos                            0.199530\n",
      "estoque                           0.205265\n",
      "limiteEmpresaAnaliseCredito       0.240776\n",
      "capitalSocial                     0.355262\n",
      "titulosEmAberto                   0.531340 \n",
      "\n",
      "                             valorAprovado\n",
      "percentualProtestos               0.008198\n",
      "eprimeira                         0.014801\n",
      "dashboardCorrelacao               0.030369\n",
      "valorSolicitado                   0.048894\n",
      "anoFundacao                       0.052694\n",
      "margemBrutaAcumulada              0.059794\n",
      "diferencaPercentualRisco          0.060300\n",
      "percentualRisco                   0.060300\n",
      "maiorAtraso                       0.067067\n",
      "totalAtivo                        0.070653\n",
      "scorePontualidade                 0.081615\n",
      "ativoCirculante                   0.090800\n",
      "prazoMedioRecebimentoVendas       0.099644\n",
      "totalPatrimonioLiquido            0.101533\n",
      "endividamento                     0.141683\n",
      "margemBruta                       0.173502\n",
      "periodoDemonstrativoEmMeses       0.182527\n",
      "faturamentoBruto                  0.188339\n",
      "custos                            0.199530\n",
      "estoque                           0.205265\n",
      "limiteEmpresaAnaliseCredito       0.240776\n",
      "capitalSocial                     0.355262\n",
      "titulosEmAberto                   0.531340 \n",
      "\n",
      "                             valorAprovado\n",
      "percentualProtestos               0.008198\n",
      "eprimeira                         0.014801\n",
      "dashboardCorrelacao               0.030369\n",
      "valorSolicitado                   0.048894\n",
      "anoFundacao                       0.052694\n",
      "diferencaPercentualRisco          0.060300\n",
      "percentualRisco                   0.060300\n",
      "maiorAtraso                       0.067067\n",
      "totalAtivo                        0.070653\n",
      "scorePontualidade                 0.081615\n",
      "ativoCirculante                   0.090800\n",
      "prazoMedioRecebimentoVendas       0.099644\n",
      "totalPatrimonioLiquido            0.101533\n",
      "endividamento                     0.141683\n",
      "margemBruta                       0.173502\n",
      "periodoDemonstrativoEmMeses       0.182527\n",
      "faturamentoBruto                  0.188339\n",
      "custos                            0.199530\n",
      "estoque                           0.205265\n",
      "limiteEmpresaAnaliseCredito       0.240776\n",
      "capitalSocial                     0.355262\n",
      "titulosEmAberto                   0.531340 \n",
      "\n",
      "                             valorAprovado\n",
      "percentualProtestos               0.008198\n",
      "eprimeira                         0.014801\n",
      "dashboardCorrelacao               0.030369\n",
      "valorSolicitado                   0.048894\n",
      "anoFundacao                       0.052694\n",
      "diferencaPercentualRisco          0.060300\n",
      "percentualRisco                   0.060300\n",
      "maiorAtraso                       0.067067\n",
      "scorePontualidade                 0.081615\n",
      "ativoCirculante                   0.090800\n",
      "prazoMedioRecebimentoVendas       0.099644\n",
      "totalPatrimonioLiquido            0.101533\n",
      "endividamento                     0.141683\n",
      "margemBruta                       0.173502\n",
      "periodoDemonstrativoEmMeses       0.182527\n",
      "faturamentoBruto                  0.188339\n",
      "custos                            0.199530\n",
      "estoque                           0.205265\n",
      "limiteEmpresaAnaliseCredito       0.240776\n",
      "capitalSocial                     0.355262\n",
      "titulosEmAberto                   0.531340 \n",
      "\n",
      "                             valorAprovado\n",
      "percentualProtestos               0.008198\n",
      "eprimeira                         0.014801\n",
      "dashboardCorrelacao               0.030369\n",
      "valorSolicitado                   0.048894\n",
      "anoFundacao                       0.052694\n",
      "diferencaPercentualRisco          0.060300\n",
      "percentualRisco                   0.060300\n",
      "maiorAtraso                       0.067067\n",
      "scorePontualidade                 0.081615\n",
      "prazoMedioRecebimentoVendas       0.099644\n",
      "totalPatrimonioLiquido            0.101533\n",
      "endividamento                     0.141683\n",
      "margemBruta                       0.173502\n",
      "periodoDemonstrativoEmMeses       0.182527\n",
      "faturamentoBruto                  0.188339\n",
      "custos                            0.199530\n",
      "estoque                           0.205265\n",
      "limiteEmpresaAnaliseCredito       0.240776\n",
      "capitalSocial                     0.355262\n",
      "titulosEmAberto                   0.531340 \n",
      "\n",
      "                             valorAprovado\n",
      "percentualProtestos               0.008198\n",
      "eprimeira                         0.014801\n",
      "dashboardCorrelacao               0.030369\n",
      "valorSolicitado                   0.048894\n",
      "anoFundacao                       0.052694\n",
      "diferencaPercentualRisco          0.060300\n",
      "percentualRisco                   0.060300\n",
      "maiorAtraso                       0.067067\n",
      "scorePontualidade                 0.081615\n",
      "prazoMedioRecebimentoVendas       0.099644\n",
      "totalPatrimonioLiquido            0.101533\n",
      "margemBruta                       0.173502\n",
      "periodoDemonstrativoEmMeses       0.182527\n",
      "faturamentoBruto                  0.188339\n",
      "custos                            0.199530\n",
      "estoque                           0.205265\n",
      "limiteEmpresaAnaliseCredito       0.240776\n",
      "capitalSocial                     0.355262\n",
      "titulosEmAberto                   0.531340 \n",
      "\n",
      "                             valorAprovado\n",
      "percentualProtestos               0.008198\n",
      "eprimeira                         0.014801\n",
      "dashboardCorrelacao               0.030369\n",
      "valorSolicitado                   0.048894\n",
      "anoFundacao                       0.052694\n",
      "diferencaPercentualRisco          0.060300\n",
      "percentualRisco                   0.060300\n",
      "maiorAtraso                       0.067067\n",
      "scorePontualidade                 0.081615\n",
      "prazoMedioRecebimentoVendas       0.099644\n",
      "totalPatrimonioLiquido            0.101533\n",
      "periodoDemonstrativoEmMeses       0.182527\n",
      "faturamentoBruto                  0.188339\n",
      "custos                            0.199530\n",
      "estoque                           0.205265\n",
      "limiteEmpresaAnaliseCredito       0.240776\n",
      "capitalSocial                     0.355262\n",
      "titulosEmAberto                   0.531340 \n",
      "\n",
      "                             valorAprovado\n",
      "percentualProtestos               0.008198\n",
      "eprimeira                         0.014801\n",
      "dashboardCorrelacao               0.030369\n",
      "valorSolicitado                   0.048894\n",
      "anoFundacao                       0.052694\n",
      "diferencaPercentualRisco          0.060300\n",
      "percentualRisco                   0.060300\n",
      "maiorAtraso                       0.067067\n",
      "scorePontualidade                 0.081615\n",
      "prazoMedioRecebimentoVendas       0.099644\n",
      "totalPatrimonioLiquido            0.101533\n",
      "periodoDemonstrativoEmMeses       0.182527\n",
      "custos                            0.199530\n",
      "estoque                           0.205265\n",
      "limiteEmpresaAnaliseCredito       0.240776\n",
      "capitalSocial                     0.355262\n",
      "titulosEmAberto                   0.531340 \n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 7569 entries, 0 to 8961\n",
      "Data columns (total 22 columns):\n",
      " #   Column                       Non-Null Count  Dtype  \n",
      "---  ------                       --------------  -----  \n",
      " 0   maiorAtraso                  7569 non-null   int64  \n",
      " 1   percentualProtestos          6360 non-null   float64\n",
      " 2   prazoMedioRecebimentoVendas  7569 non-null   int64  \n",
      " 3   titulosEmAberto              7569 non-null   float64\n",
      " 4   valorSolicitado              7569 non-null   float64\n",
      " 5   status                       7569 non-null   object \n",
      " 6   definicaoRisco               7569 non-null   object \n",
      " 7   diferencaPercentualRisco     7569 non-null   float64\n",
      " 8   percentualRisco              7569 non-null   float64\n",
      " 9   dashboardCorrelacao          7569 non-null   float64\n",
      " 10  valorAprovado                7569 non-null   float64\n",
      " 11  totalPatrimonioLiquido       4388 non-null   float64\n",
      " 12  estoque                      4388 non-null   float64\n",
      " 13  periodoDemonstrativoEmMeses  7565 non-null   float64\n",
      " 14  anoFundacao                  7569 non-null   float64\n",
      " 15  intervaloFundacao            7569 non-null   object \n",
      " 16  capitalSocial                7569 non-null   float64\n",
      " 17  restricoes                   7569 non-null   object \n",
      " 18  empresa_MeEppMei             7569 non-null   object \n",
      " 19  scorePontualidade            7569 non-null   float64\n",
      " 20  limiteEmpresaAnaliseCredito  7569 non-null   float64\n",
      " 21  eprimeira                    7569 non-null   bool   \n",
      "dtypes: bool(1), float64(14), int64(2), object(5)\n",
      "memory usage: 1.3+ MB\n"
     ]
    }
   ],
   "source": [
    "#Remove MultiCollinearity in input\n",
    "arquivo = pd.read_csv('./solicitacoescredito.csv')\n",
    "df=arquivo.loc[arquivo['status'].isin(['AprovadoAnalista','AprovadoComite'])]\n",
    "\n",
    "df=df.drop(['numero_solicitacao','razaoSocial','nomeFantasia','cnpjSemTraco','dataAprovadoEmComite','dataAprovadoNivelAnalista'],axis=1)\n",
    "\n",
    "\n",
    "invalidDates = [\n",
    "    '0019-02-06T03:06:00',\n",
    "    '0001-01-01T03:06:00',\n",
    "    '0001-01-01T06:12:00',\n",
    "    '0019-02-06T03:06:00',\n",
    "    '0219-12-31T03:06:00'\n",
    "]\n",
    "\n",
    "for d in invalidDates:\n",
    "    df['periodoBalanco']=df['periodoBalanco'].replace(d,np.nan)\n",
    "df['periodoBalanco']=pd.to_datetime(df['periodoBalanco'],errors='coerce')\n",
    "df['primeiraCompra']=pd.to_datetime(df['primeiraCompra'],errors='coerce')\n",
    "\n",
    "\n",
    "\n",
    "df['eprimeira']=df['primeiraCompra'].isna()\n",
    "df=df.drop(['primeiraCompra'],axis=1)\n",
    "\n",
    "ftRemover = MultiCollinearityEliminator(df,'valorAprovado',0.7)\n",
    "df=ftRemover.autoEliminateMulticollinearity()\n",
    "df=df.drop(['periodoBalanco'],axis=1)\n",
    "df.info()\n",
    "df=pd.get_dummies(df, columns=[\"definicaoRisco\",\"empresa_MeEppMei\",\"restricoes\",\"intervaloFundacao\",\"status\"], prefix=[\"definicaoRisco\",\"mei\",\"restricoes\",\"intervaloFundacao\",\"status\"])\n",
    "#Create dummy columns\n",
    "df=df.fillna(method='bfill',axis=1)\n",
    "y = df['valorAprovado']\n",
    "X= df.drop(['valorAprovado'], axis=1)\n",
    "X = StandardScaler().fit_transform(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest Neighbors\n",
      "mean_squared_error [-1.61531909e+11 -9.59256252e+10 -8.59395890e+10 -1.77799597e+11\n",
      " -2.62944657e+11]\n",
      "mean_absolute_percentage_error [-4.12025197e+00 -3.31671967e+18 -3.62572654e+01 -1.17200677e+18\n",
      " -1.10883134e+00]\n",
      "Linear SVM\n",
      "mean_squared_error [-1.20622699e+11 -1.48622649e+11 -1.80134224e+11 -5.31904438e+11\n",
      " -6.13619665e+11]\n",
      "mean_absolute_percentage_error [-1.38547075e+00 -2.38644983e+17 -2.68139979e+01 -2.09064866e+17\n",
      " -1.10742738e+00]\n",
      "RBF SVM\n",
      "mean_squared_error [-1.20644613e+11 -1.48631071e+11 -1.80245871e+11 -5.31957074e+11\n",
      " -6.13681622e+11]\n",
      "mean_absolute_percentage_error [-1.39825926e+00 -2.37972404e+17 -2.65675406e+01 -2.08235090e+17\n",
      " -1.11341931e+00]\n",
      "Gamma SVRDecision Tree\n",
      "mean_squared_error [-4.53917982e+10 -3.42286087e+10 -8.25279025e+09 -3.18694606e+10\n",
      " -5.47756642e+10]\n",
      "mean_absolute_percentage_error [-6.71145870e-01 -4.16623485e+18 -2.77055685e+01 -1.24807120e+18\n",
      " -6.34080050e-01]\n",
      "Random Forest\n",
      "mean_squared_error [-7.71164882e+10 -8.01582655e+10 -8.30519395e+10 -2.51213314e+11\n",
      " -3.43425893e+11]\n",
      "mean_absolute_percentage_error [-8.12389599e+00 -2.20590168e+18 -1.41450538e+02 -1.43195578e+18\n",
      " -3.88189148e+00]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural Net\n",
      "mean_squared_error [-1.43419924e+11 -1.22217246e+11 -1.28118770e+11 -3.74217614e+11\n",
      " -4.35819943e+11]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_absolute_percentage_error [-4.69532840e+00 -1.94183659e+18 -1.53264952e+01 -1.04897980e+18\n",
      " -2.69348171e+00]\n",
      "AdaBoost\n",
      "mean_squared_error [-8.52233879e+10 -2.99015269e+10 -3.57981448e+10 -5.75115231e+10\n",
      " -1.00916712e+11]\n",
      "mean_absolute_percentage_error [-1.10618151e+01 -4.21244150e+18 -4.52878580e+02 -1.99408552e+18\n",
      " -5.72637403e+00]\n"
     ]
    }
   ],
   "source": [
    "names = [\"Nearest Neighbors\", \n",
    "         \"Linear SVM\", \n",
    "         \"RBF SVM\",\n",
    "         \"Gamma SVR\"\n",
    "         #\"Gaussian Process\",\n",
    "         \"Decision Tree\", \n",
    "         \"Random Forest\", \n",
    "         \"Neural Net\", \n",
    "         \"AdaBoost\",\n",
    "         #\"Naive Bayes\", \n",
    "         #\"QDA\"\n",
    "        ]\n",
    "\n",
    "classifiers = [\n",
    "    KNeighborsRegressor(3),\n",
    "    SVR(kernel=\"linear\", C=0.025),\n",
    "    SVR(gamma=2, C=1),\n",
    "    #GaussianProcessClassifier(1.0 * RBF(1.0)),\n",
    "    DecisionTreeRegressor(max_depth=5),\n",
    "    RandomForestRegressor(max_depth=5, n_estimators=10, max_features=1),\n",
    "    MLPRegressor(alpha=1, max_iter=1000),\n",
    "    AdaBoostRegressor(),\n",
    "    #QuadraticDiscriminantAnalysis()\n",
    "    ]\n",
    "l=len(classifiers)\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2, random_state=42)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "\n",
    "for name, clf in zip(names, classifiers):\n",
    "    clf.fit(X_train, y_train)\n",
    "    score = cross_val_score(clf,X,y,scoring = \"neg_mean_squared_error\")\n",
    "    \n",
    "    from sklearn.metrics import mean_absolute_percentage_error\n",
    "\n",
    "    print (name)\n",
    "    print (\"mean_squared_error\",score)\n",
    "    score = cross_val_score(clf,X,y,scoring = \"neg_mean_absolute_percentage_error\")\n",
    "\n",
    "    print (\"mean_absolute_percentage_error\",score)\n",
    "    y_predict=clf.predict(X_test)\n",
    "    saida = { \"test\": y_test, \"predict\" : y_predict}\n",
    "    newDf= pd.DataFrame(saida)\n",
    "    newDf.head()\n",
    "    \n",
    "    \n",
    "\n",
    "#plt.xlabel('cake size and toppings')\n",
    "#plt.ylabel('cake price')\n",
    "#    predictions = clf.predict(y_test)\n",
    "#    v1,v2=[],[]\n",
    "#    for i,prediction in enumerate(predictions):\n",
    "#        print(f'predicted value : {prediction[0]:.02f} vs target value: {y_test[i][0]}')\n",
    "#    v1.append(prediction[0])\n",
    " #   v2.append(y_test[i][0])\n",
    "#print(f'R-squared : {model.score(x1_test,y_test)}')\n",
    "#ax.plot(v1,color='g',linestyle='--')\n",
    "#ax.plot(v2,color='r',linestyle='--')\n",
    "#plt.grid(True,linestyle='-',linewidth='0.5')\n",
    "#plt.show()\n",
    "#plt.close(f)\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "  \n",
    "    \n",
    "   \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.metrics import SCORERS\n",
    "print(SCORERS.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newDf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
